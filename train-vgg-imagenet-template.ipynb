{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**based on: train-vgg-imagenet-template version 1.0, Jonas Rauber, 2017-02-20**\n",
    "\n",
    "Please let me now of any ideas to improve this template. I recommend to not remove the version number and to check for new versions of this template at https://github.com/jonasrauber/tensorflow-imagenet when running into problems or starting a new notebook. VGG19 is just an example that can be easily replaced with other networks. See comments to specify paths, increase data io performance, adjust batch size, control logging or specify the variables to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:39:50.744617",
     "start_time": "2017-02-20T11:39:50.734334"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify the path to your local clone of https://github.com/tensorflow/models,\n",
    "# which is used to load ImageNet and apply VGG preprocessing\n",
    "TENSORFLOW_MODELS_SLIM = 'TODO'\n",
    "\n",
    "# specify the path of the ImageNet tfrecords files\n",
    "IMAGENET_DATA = '/gpfs01/bethge/data/imagenet'\n",
    "\n",
    "# specify the path to your initial checkpoint to restore pretrained models, e.g. VGG19\n",
    "INITIAL_CHECKPOINT = '/gpfs01/bethge/data/tf-model-checkpoints/vgg_19.ckpt'\n",
    "\n",
    "# specify the directory where checkpoints and summaries are stored; start TensorBoard with access to this directory\n",
    "LOGDIR = 'TODO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:39:54.175364",
     "start_time": "2017-02-20T11:39:50.749607"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ipython configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# standard library\n",
    "import sys\n",
    "\n",
    "# third-party packages\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# local modules\n",
    "IMPORT_PATHS = [TENSORFLOW_MODELS_SLIM]\n",
    "sys.path.extend(set(IMPORT_PATHS) - set(sys.path))\n",
    "from datasets import imagenet\n",
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:39:54.241489",
     "start_time": "2017-02-20T11:39:54.181245"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_19_train(inputs,\n",
    "                 is_training=True,\n",
    "                 dropout_keep_prob=0.5,\n",
    "                 scope='vgg_19',\n",
    "                 reuse=False):\n",
    "    \"\"\"VGG19 implementation using fully-connected layers\n",
    "    \n",
    "    Fully-connected layers are currently faster than 1x1 convolutions\n",
    "    and should be used when VGG is part of a training pipeline. During\n",
    "    evaluation, you might want to use the corresponding fully-convolution\n",
    "    network to be able to apply it to other image sizes.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, 'vgg_19', [inputs], reuse=reuse) as sc:\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d]):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.flatten(net)\n",
    "            net = slim.fully_connected(net, 4096, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "            net = slim.fully_connected(net, 4096, scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "            net = slim.fully_connected(net, 1000, activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:39:54.482082",
     "start_time": "2017-02-20T11:39:54.244167"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    with tf.device('/cpu:0'):\n",
    "        dataset = imagenet.get_split('train', IMAGENET_DATA)\n",
    "        provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            dataset,\n",
    "            num_readers=2, # controls the speed at which data is loaded\n",
    "            shuffle=True,\n",
    "            common_queue_capacity=256,\n",
    "            common_queue_min=128)\n",
    "        image, label = provider.get(['image', 'label'])\n",
    "        \n",
    "        # preprocess the image\n",
    "        image = vgg_preprocessing.preprocess_image(\n",
    "            image,\n",
    "            224,\n",
    "            224,\n",
    "            is_training=True,\n",
    "            resize_side_min=256,\n",
    "            resize_side_max=512)\n",
    "        \n",
    "        # preprocess the label\n",
    "        label = tf.sub(label, 1) # 1..1000 to 0..999\n",
    "        label = tf.reshape(label, (1,))\n",
    "\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=32, # specify the batch size here\n",
    "        num_threads=8, # controls the speed at which images are preprocessed\n",
    "        capacity=128)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:39:57.558284",
     "start_time": "2017-02-20T11:39:54.484731"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # load the data\n",
    "    images, labels = get_training_data()\n",
    "    \n",
    "    # apply the model\n",
    "    predictions = vgg_19_train(images, is_training=True)\n",
    "    \n",
    "    # define the loss\n",
    "    loss = slim.losses.sparse_softmax_cross_entropy(predictions, labels)\n",
    "    total_loss = slim.losses.get_total_loss()\n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    \n",
    "    # create the train op\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer) # specify variables to train here\n",
    "    \n",
    "    # summaries\n",
    "    tf.summary.histogram('predictions', predictions)\n",
    "    tf.summary.scalar('total_loss', total_loss)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    # define an init function that restores the pretrained VGG\n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        INITIAL_CHECKPOINT,\n",
    "        slim.get_model_variables(),\n",
    "        reshape_variables=True) # reshape variables because the checkpoint is for a fully-convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T11:40:21.881981",
     "start_time": "2017-02-20T11:39:57.564360"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this will run forever: stop it using Kernel -> Interrupt\n",
    "# the first few steps will take longer, until the queues are filled\n",
    "slim.learning.train(\n",
    "    train_op,\n",
    "    LOGDIR,\n",
    "    graph=g,\n",
    "    init_fn=init_fn,\n",
    "    log_every_n_steps=1, # increase to avoid too many log statements\n",
    "    summary_op=summary_op,\n",
    "    save_summaries_secs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
