{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**based on: train-vgg-imagenet-template version 2.0, Jonas Rauber, 2017-02-20**\n",
    "\n",
    "Please let me now of any ideas to improve this template. I recommend to not remove the version number and to check for new versions of this template at https://github.com/jonasrauber/tensorflow-imagenet when running into problems or starting a new notebook. VGG19 is just an example that can be easily replaced with other networks. See comments to specify paths, increase data io performance, adjust batch size, control logging or specify the variables to train.\n",
    "\n",
    "Use TensorFlow 1.0 or higher.\n",
    "\n",
    "At the moment, the slim directory in the tensorflow/models repository needs to be upgraded manually to TensorFlow 1.0 using \"python ~/bin/tf_upgrade.py --intree slim --outtree slim-upgraded\" (see https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility) [Output should say \"Converted 50 files\"]. Hopefully, the tensorflow/models repository on GitHub gets upgraded soon so that this won't be necessary in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:48.555200",
     "start_time": "2017-02-20T16:06:48.514937"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify the path to your local clone of https://github.com/tensorflow/models,\n",
    "# which is used to load ImageNet and apply VGG preprocessing\n",
    "TENSORFLOW_MODELS = 'PLEASE SPECIFY'\n",
    "\n",
    "# specify the path of the ImageNet tfrecords files\n",
    "IMAGENET_DATA = '/gpfs01/bethge/data/imagenet'\n",
    "\n",
    "# specify the path to your initial checkpoint to restore pretrained models, e.g. VGG19\n",
    "INITIAL_CHECKPOINT = '/gpfs01/bethge/data/tf-model-checkpoints/vgg_19.ckpt'\n",
    "\n",
    "# specify the directory where checkpoints and summaries are stored; start TensorBoard with access to this directory\n",
    "LOGDIR = 'PLEASE SPECIFY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:49.208195",
     "start_time": "2017-02-20T16:06:49.049950"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ipython configuration\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# standard library\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# third-party packages\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# local modules\n",
    "IMPORT_PATHS = [os.path.join(TENSORFLOW_MODELS, 'slim-upgraded')]\n",
    "sys.path.extend(set(IMPORT_PATHS) - set(sys.path))\n",
    "from datasets import imagenet\n",
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:49.899872",
     "start_time": "2017-02-20T16:06:49.829034"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is NOT the same as the vgg_19 in tensorflow/models or tf.contrib.slim\n",
    "def vgg_19(inputs,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           scope='vgg_19',\n",
    "           reuse=False):\n",
    "    \"\"\"VGG19 implementation using fully-connected layers\n",
    "    \n",
    "    Fully-connected layers are currently faster than 1x1 convolutions\n",
    "    and should be used when VGG is part of a training pipeline. During\n",
    "    evaluation, you might want to use the corresponding fully-convolution\n",
    "    network to be able to apply it to other image sizes.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, 'vgg_19', [inputs], reuse=reuse) as sc:\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d]):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.flatten(net)\n",
    "            net = slim.fully_connected(net, 4096, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "            net = slim.fully_connected(net, 4096, scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "            net = slim.fully_connected(net, 1000, activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:50.501216",
     "start_time": "2017-02-20T16:06:50.450607"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    with tf.device('/cpu:0'):\n",
    "        dataset = imagenet.get_split('train', IMAGENET_DATA)\n",
    "        provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            dataset,\n",
    "            num_readers=2, # controls the speed at which data is loaded\n",
    "            shuffle=True,\n",
    "            common_queue_capacity=256,\n",
    "            common_queue_min=128)\n",
    "        image, label = provider.get(['image', 'label'])\n",
    "        \n",
    "        # preprocess the image\n",
    "        image = vgg_preprocessing.preprocess_image(\n",
    "            image,\n",
    "            224,\n",
    "            224,\n",
    "            is_training=True,\n",
    "            resize_side_min=256,\n",
    "            resize_side_max=512)\n",
    "        \n",
    "        # preprocess the label\n",
    "        label = tf.subtract(label, 1) # 1..1000 to 0..999\n",
    "\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label],\n",
    "        batch_size=32, # specify the batch size here\n",
    "        num_threads=8, # controls the speed at which images are preprocessed\n",
    "        capacity=128)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:51.047793",
     "start_time": "2017-02-20T16:06:51.010319"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_k_accuracy(labels, predictions, k, name='top_k_accuracy'):\n",
    "    \"\"\"Something like this should be in tf.metrics, but as far as I can see, there is no such function.\"\"\"\n",
    "    with tf.name_scope(name, 'top_k_accuracy'):\n",
    "        correct = tf.nn.in_top_k(predictions, labels, k=k)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:06:54.579319",
     "start_time": "2017-02-20T16:06:51.648745"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # load the data\n",
    "    images, labels = get_training_data()\n",
    "    \n",
    "    # apply the model\n",
    "    predictions = vgg_19(images, is_training=True)\n",
    "    \n",
    "    # define the loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels, predictions)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    \n",
    "    # define the metrics\n",
    "    top5_accuracy = top_k_accuracy(labels, predictions, k=5)\n",
    "    top1_accuracy = top_k_accuracy(labels, predictions, k=1)\n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-4)\n",
    "    \n",
    "    # create the train op\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer) # specify variables to train here\n",
    "    \n",
    "    # create summaries\n",
    "    tf.summary.histogram('predictions', predictions)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('total_loss', total_loss)\n",
    "    tf.summary.scalar('top5_accuracy', top5_accuracy)\n",
    "    tf.summary.scalar('top1_accuracy', top1_accuracy)\n",
    "    \n",
    "    # define an init function that restores the pretrained VGG\n",
    "    init_fn = slim.assign_from_checkpoint_fn(\n",
    "        INITIAL_CHECKPOINT,\n",
    "        slim.get_model_variables(),\n",
    "        reshape_variables=True) # reshape variables because the checkpoint is for a fully-convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-20T16:07:40.470097",
     "start_time": "2017-02-20T16:06:55.621992"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this will run forever: stop it using Kernel -> Interrupt\n",
    "# the first few steps will take longer, until the queues are filled\n",
    "slim.learning.train(\n",
    "    train_op,\n",
    "    LOGDIR,\n",
    "    graph=g,\n",
    "    init_fn=init_fn,\n",
    "    log_every_n_steps=1, # increase to avoid too many log statements\n",
    "    save_summaries_secs=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
